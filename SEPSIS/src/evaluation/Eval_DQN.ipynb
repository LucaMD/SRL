{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "### import overall usefull libraries\n",
    "import os\n",
    "import platform\n",
    "import copy\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "### import specific libraries for this notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### import specific functions from torck and sklearn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import joblib\n",
    "\n",
    "### Imports that are also performed in util.py\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "# automatically reload python fiels (util.py and conf.py) when they are changed.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import from parent directory with a little help from sys.path.insert()\n",
    "sys.path.insert(0, '..') \n",
    "\n",
    "### from util.py (file which once contained all classes and functions):\n",
    "from util import * \n",
    "\n",
    "### Configuration file to determine root directory \n",
    "import conf\n",
    "\n",
    "### check for GPU's\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "### Check everything\n",
    "conf.print_python_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select experiment and experiment grid number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "### Experiment name\n",
    "exp_name = 'FINAL'\n",
    "exp_grid_run = 1\n",
    "\n",
    "###################\n",
    "# OPTIONAL:\n",
    "continued = False\n",
    "continued_grid = 0\n",
    "orig_exp_name = exp_name\n",
    "# load experiment\n",
    "if continued == True:\n",
    "    exp_name =  os.path.join(exp_name+\"_\"+str(continued_grid)+\"_continued\")\n",
    "    print('CONTINUED experiment name: ', exp_name)\n",
    "else:\n",
    "    print('Experiment name: ', exp_name)\n",
    "    \n",
    "###################\n",
    "### Load model config\n",
    "model_config_file = orig_exp_name + '/models/' + exp_name + '_' + str(exp_grid_run) +'_config.csv'\n",
    "model_config_df = pd.read_csv(os.path.join(conf.EXP_DIR, model_config_file), sep=',')\n",
    "model_config = model_config_df.to_dict()\n",
    "from pprint import pprint\n",
    "pprint(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# set model location\n",
    "exp_model = orig_exp_name + '/models/' + exp_name + '_' + str(exp_grid_run) + '_model.chk'  \n",
    "\n",
    "# set model results directories\n",
    "exp_resultsdir = os.path.join(conf.EXP_DIR, str(orig_exp_name) + '/models/' + str(exp_name) + '_' + str(exp_grid_run) +'/')\n",
    "exp_figuresdir = os.path.join(conf.EXP_DIR, str(orig_exp_name) + '/figures/')\n",
    "\n",
    "###################\n",
    "# ASSIGN the CONFIG settings from the trained model\n",
    "config = { \n",
    "          'state_dim' :   model_config['state_dim'][0],\n",
    "          'action_dim' :  model_config['action_dim'][0],\n",
    "          'gamma' :       model_config['gamma'][0],\n",
    "          'hidden_dim' :  model_config['hidden_dim'][0],\n",
    "          'num_hidden' :  model_config['num_hidden'][0],\n",
    "          'drop_prob' :   model_config['drop_prob'][0],\n",
    "          'option' :      model_config['option'][0],\n",
    "          'num_epochs':   model_config['num_epochs'][0],\n",
    "          'interim_step': model_config['tracking_step_interim_model'][0]\n",
    "    \n",
    "         }\n",
    "\n",
    "###################\n",
    "# Define model structure to match the configuration from \"best model\" from 06_train_model.ipynb\n",
    "model = dueling_net(D_in = config['state_dim'], \n",
    "                    H = config['hidden_dim'], \n",
    "                    D_out = config['action_dim'],\n",
    "                    drop_prob = config['drop_prob'],\n",
    "                    num_hidden = config['num_hidden'],\n",
    "                    option = config['option'])\n",
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "# This is horrible practice: https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python\n",
    "if not os.path.exists(os.path.join(conf.EXP_DIR, orig_exp_name)):\n",
    "    raise Exception('Cannot find experiment directory, run create_exp_dataset prior to running this file')\n",
    "else:\n",
    "    exp_dir = os.path.join(conf.EXP_DIR, orig_exp_name)\n",
    "    ############################################\n",
    "    # load data files    \n",
    "    try:\n",
    "        data_dict = joblib.load(os.path.join(exp_dir, 'data/FINAL_data_dict.pkl'))\n",
    "    except:\n",
    "        raise Exception('Cannot load dataset, run the create_exp_dataset Notebook to create new data pickle files ')\n",
    "    try:\n",
    "        # Action probabilities of physician's action used for intermediate evaluateion\n",
    "        train_pi_behavior = pd.read_pickle(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_' + 'train' + 'data.pkl')) # pi_evaluation\n",
    "        val_pi_behavior = pd.read_pickle(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_' + 'val' + 'data.pkl')) # pi_evaluation\n",
    "        test_pi_behavior = pd.read_pickle(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_' + 'test' + 'data.pkl')) # pi_evaluation\n",
    "    except: \n",
    "        raise Exception('Cannot load KNN files, run Physician_KNN.py to create new KNN pickle files')\n",
    "    try:\n",
    "        # dataset MDP Q function (FQI-SARSA)\n",
    "        train_MDP_Q = pd.read_pickle(os.path.join(exp_dir, 'FQI/FQI_QValues_continuous_' + 'train' + 'data.pkl'))\n",
    "        val_MDP_Q = pd.read_pickle(os.path.join(exp_dir, 'FQI/FQI_QValues_continuous_' + 'val' + 'data.pkl'))\n",
    "        test_MDP_Q = pd.read_pickle(os.path.join(exp_dir, 'FQI/FQI_QValues_continuous_' + 'test' + 'data.pkl'))\n",
    "    except: \n",
    "        raise Exception('Cannot load FQI files, run Physician_FQI.py to create new FQI pickle files')\n",
    "        \n",
    "# print!\n",
    "print(\"Experiment \\\"\"+ str(exp_name) + \"\\\" loaded with grid: \" + str(exp_grid_run))\n",
    "print(\"model: \", exp_model)\n",
    "print(\"exp_resultsdir: \", exp_resultsdir)\n",
    "print(\"exp_figuresdir: \", exp_figuresdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show interim models action distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment \\\"\"+ str(exp_name) + \"\\\" loaded with grid: \" + str(exp_grid_run))\n",
    "interim_model_list = np.arange(config['interim_step'], config['num_epochs']+config['interim_step'], config['interim_step'])\n",
    "count=0\n",
    "for interim_model in interim_model_list:\n",
    "    try:\n",
    "        count+=1\n",
    "        exp_model = exp_name + '_' + str(exp_grid_run) + '_interim_'+ str(interim_model) +'_iteration_model.chk'\n",
    "        selected_model = os.path.join(exp_resultsdir, exp_model)\n",
    "        ############################################\n",
    "        # Load model    \n",
    "        if use_gpu:\n",
    "            model = model.cuda()\n",
    "            model.load_state_dict(torch.load(selected_model))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(selected_model, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        ############################################\n",
    "        ### visual inspection of action and action probability distribution in the dataset\n",
    "        print(\"interim model:\" +str(interim_model))\n",
    "        # Create multiplot\n",
    "        plt.figure(figsize=(15, 3))\n",
    "\n",
    "        # best action distribution\n",
    "        outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, 'train', use_gpu) \n",
    "        plt.subplot(131)\n",
    "        pd.Series(data_dict['train']['action']).hist(bins=21,alpha=0.5)\n",
    "        pd.Series(best_actions).hist(bins=21,alpha=0.5)\n",
    "        plt.ylim(0,20000)\n",
    "        plt.title(\"TRAIN -  DQN best action distribution\")\n",
    "\n",
    "        # best action distribution\n",
    "        outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, 'val', use_gpu) \n",
    "        plt.subplot(132)\n",
    "        pd.Series(data_dict['val']['action']).hist(bins=21,alpha=0.5)\n",
    "        pd.Series(best_actions).hist(bins=21,alpha=0.5)\n",
    "        plt.ylim(0,20000)\n",
    "        plt.title(\"VAL -  DQN best action distribution\")\n",
    "\n",
    "        # best action distribution\n",
    "        outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, 'test', use_gpu) \n",
    "        plt.subplot(133)\n",
    "        pd.Series(data_dict['test']['action']).hist(bins=21,alpha=0.5)\n",
    "        pd.Series(best_actions).hist(bins=21,alpha=0.5)\n",
    "        plt.ylim(0,20000)\n",
    "        plt.title(\"TEST -  DQN best action distribution\")\n",
    "\n",
    "        # visual inspection\n",
    "        plt.show()\n",
    "        \n",
    "    ### Catch \"Still training error\"   \n",
    "    except:\n",
    "        print(\"End of interim model list\")\n",
    "        break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "interim_model = False\n",
    "interim = 220000\n",
    "\n",
    "###################\n",
    "# OPTIONAL: Load INTERIM model, else use final model as defined above\n",
    "if interim_model:\n",
    "    exp_model = orig_exp_name + '/models/' + exp_name + '_' + str(exp_grid_run) + '/' + exp_name + '_' + str(exp_grid_run) + '_interim_' + str(interim) + '_iteration_model.chk'\n",
    "else:\n",
    "    exp_model = orig_exp_name + '/models/' + exp_name + '_' + str(exp_grid_run) + '_model.chk'  \n",
    "###################\n",
    "### LOAD MODEL file and MODEL CONFIG FILE\n",
    "selected_model = os.path.join(conf.EXP_DIR, exp_model)\n",
    "\n",
    "###################\n",
    "# Load model    \n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(selected_model))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(selected_model, map_location=lambda storage, loc: storage))\n",
    "print(\"loaded model: \" + exp_model)\n",
    "print(\"Finished at: \" + str(datetime.now()) + \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model analysis\n",
    "    1) PLOT action distributions \n",
    "    2) Create files for deep Model Inspection\n",
    "    3) Perform final model WIS and WDR analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loaded model: \" + exp_model)\n",
    "eval_types = ['train', 'val', 'test']\n",
    "for eval_type in eval_types:\n",
    "    # gamma\n",
    "    gamma = config['gamma']\n",
    "        \n",
    "    # action probabilities of physician's action used for intermediate evaluateion\n",
    "    pi_behavior = pd.read_pickle(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_' + eval_type + 'data.pkl'))\n",
    "    \n",
    "    # eval dataset MDP Q function\n",
    "    Q = pd.read_pickle(os.path.join(exp_dir, 'FQI/FQI_QValues_continuous_' + eval_type + 'data.pkl'))\n",
    "\n",
    "    ############################################\n",
    "    # Model evaluation\n",
    "    outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, eval_type, use_gpu)   \n",
    "    print(outputs.shape)\n",
    "\n",
    "    ############################################\n",
    "    # keep copy of Q VALUES\n",
    "    results_df = pd.DataFrame.from_records(outputs)\n",
    "    results_df = np.around(results_df,3)\n",
    "    results_df.columns =  ['Q' + str(i) for i in np.unique(data_dict[eval_type]['action'])]\n",
    "\n",
    "    # Add best action \n",
    "    results_df['best_action'] = best_actions\n",
    "\n",
    "    # Add action Q values\n",
    "    results_df['phy_action_Qvalue'] = state_Q_values\n",
    "    results_df['best_action_Qvalue'] = best_policy_values\n",
    "\n",
    "    # Add state id\n",
    "    results_df['state_id'] = data_dict[eval_type]['state_id']\n",
    "    \n",
    "    # Save\n",
    "    results_df.to_csv(os.path.join(exp_resultsdir, 'DQN_Qvalues_' + eval_type + 'data.csv'), index=False)\n",
    "    \n",
    "    ############################################\n",
    "    # keep copy of Q VALUES PROBABILITES\n",
    "    action_prob_df = pd.DataFrame.from_records(outputs_prob)\n",
    "    action_prob_df = np.around(action_prob_df,3)\n",
    "    action_prob_df.columns =  ['A' + str(i) for i in np.unique(data_dict[eval_type]['action'])]\n",
    "\n",
    "    # Add best action \n",
    "    action_prob_df['best_action'] = best_actions\n",
    "\n",
    "    # Add best action probabilites\n",
    "    action_prob_df['best_action_probability'] = best_action_probabilities\n",
    "\n",
    "    # Add state id\n",
    "    action_prob_df['state_id'] = data_dict[eval_type]['state_id']\n",
    "    \n",
    "    # Save\n",
    "    action_prob_df.to_csv(os.path.join(exp_resultsdir, 'DQN_action_prob_df_' + eval_type + 'data.csv'), index=False)\n",
    "    \n",
    "    ############################################\n",
    "    ### visual inspection of action and action probability distribution in the dataset\n",
    "    # Create multiplot\n",
    "    plt.figure(figsize=(21, 6))\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    phy_action_probabilities = pi_behavior.max(axis=1)\n",
    "    pd.Series(phy_action_probabilities*100).hist(bins=100)\n",
    "    plt.title(str(eval_type) + \" - PHYSICIAN action probability distribution\")    \n",
    "    \n",
    "    plt.subplot(222)\n",
    "    best_action_probabilities = outputs_prob.max(axis=1)\n",
    "    pd.Series(best_action_probabilities*100).hist(bins=100)\n",
    "    plt.title(str(eval_type) + \" - DQN best action probability distribution\")\n",
    "\n",
    "    plt.subplot(223)\n",
    "    pd.Series(data_dict[eval_type]['action']).hist(bins=21)\n",
    "    plt.title(str(eval_type) + \" -  PHYSICIAN action distribution\")\n",
    "\n",
    "    # best action distribution\n",
    "    plt.subplot(224)\n",
    "    pd.Series(best_actions).hist(bins=21)\n",
    "    plt.title(str(eval_type) + \" -  DQN best action distribution\")\n",
    "\n",
    "    # visual inspection\n",
    "    #plt.savefig(os.path.join(exp_figuresdir, 'Eval_DQN_histrogram_multiplot_'+ str(eval_type) +'.tiff'),dpi=200,transparent=True)\n",
    "    \n",
    "    #############################################\n",
    "    # create an output dataframe with for the Q values and action probability\n",
    "    pi_evaluation = np.around(pd.DataFrame.from_records(outputs_prob),3)\n",
    "   \n",
    "    # Perform WOPE\n",
    "    Phys_WDR, Phys_wis = eval_WDR(data_dict, eval_type, gamma, pi_behavior, pi_behavior, Q)\n",
    "    model_WDR, model_wis = eval_WDR(data_dict, eval_type, gamma, pi_evaluation, pi_behavior, Q)\n",
    "\n",
    "    # Results\n",
    "    print( str(eval_type) + \"\\nPhy WDR: \" + str(round(Phys_WDR, 4)) \n",
    "                          + \"\\nDQN WDR: \" + str(round(model_WDR, 4)) \n",
    "                          + \"\\nPhy WIS: \" + str(round(Phys_wis, 4)) \n",
    "                          + \"\\nDQN WIS: \" + str(round(model_wis, 4)))\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
