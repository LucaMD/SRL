{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "### import overall usefull libraries\n",
    "import os\n",
    "import platform\n",
    "import copy\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "### import specific libraries for this project\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import joblib\n",
    "\n",
    "### import KNN related libraries\n",
    "from sklearn.neighbors import NearestNeighbors as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "# import from parent directory with a little help from sys.path.insert()\n",
    "sys.path.insert(0, '..') \n",
    "\n",
    "### from util.py (file which once contained all classes and functions):\n",
    "from util import * # automatically reload python (e.g. util.py) file when they are changed.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Configuration file to determine root directory \n",
    "import conf\n",
    "\n",
    "# from configuration file set working directory\n",
    "os.chdir(os.path.join(conf.ROOT_DIR, 'SEPSIS'))\n",
    "\n",
    "### Check everything\n",
    "conf.print_python_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "### Experiment name\n",
    "exp_name = 'FINAL'\n",
    "\n",
    "# This is horrible practice: https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python\n",
    "if not os.path.exists(os.path.join(conf.EXP_DIR, exp_name)):\n",
    "    raise Exception('Cannot find experiment directory, run create_exp_dataset prior to running this file')\n",
    "else:\n",
    "    ############################################\n",
    "    # define experiment directory\n",
    "    exp_dir = os.path.join(conf.EXP_DIR, exp_name)\n",
    "    \n",
    "    ############################################\n",
    "    # add a KNN interim data subdirectory if needed\n",
    "    if not os.path.exists(os.path.join(exp_dir, 'KNN')):\n",
    "        os.makedirs(os.path.join(exp_dir, 'KNN'))\n",
    "    \n",
    "    ############################################\n",
    "    # load dataset    \n",
    "    try:\n",
    "        data_dict = joblib.load(os.path.join(exp_dir, 'data/FINAL_data_dict.pkl'))\n",
    "    except:\n",
    "        raise Exception('Cannot load dataset, rerun create_exp_dataset!')\n",
    "\n",
    "    # inspect it (slightly less shitty code then before, still sorry)\n",
    "    print(\"Visual inspection of data dictionary structure:\")\n",
    "    for k, v in data_dict.items():\n",
    "        if(k == 'v'): continue\n",
    "        elif(k == 'featurenames'): \n",
    "            print(v); continue\n",
    "        for k1, v1 in v.items():\n",
    "            print(k, k1)\n",
    "            \n",
    "    ############################################      \n",
    "    ### features: \n",
    "    feature_names = data_dict['featurenames']\n",
    "    print('features: ', feature_names)\n",
    "    print(\"\\nExperiment loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From paper https://arxiv.org/abs/1811.09602:\n",
    "*We define similarity of patient states using a ‘physiological distance kernel’, which is based on Euclidean distance and\n",
    "upweights certain informative features of the patient’s state. Informative features were the patient’s:*\n",
    "- *SOFA score*\n",
    "- *Lactate levels*\n",
    "- *fluid output*\n",
    "- *mean and blood pressure (MAP)*\n",
    "- *diastolic blood pressure*\n",
    "- *PaO2/FiO2 ratio*\n",
    "- *chloride levels*\n",
    "- *weight*\n",
    "- *age*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Upweighted features for KNN distance metric\n",
    "upweighted_features = ['Sofa_score', # SOFA score\n",
    "                       'Lactate',    # Lactate levels\n",
    "                       'total_UP',   # fluid output of current state\n",
    "                       'total_IV',   # iv fluid input of current state\n",
    "                       'MAP',        # mean and blood pressure (MAP)\n",
    "                       'DIA',        # diastolic blood pressure,\n",
    "                       'PF_ratio',   # PaO2/FiO2 ratio\n",
    "                       'Weight',     # weight,\n",
    "                       'Age',        # age\n",
    "                      ]\n",
    "\n",
    "# Check if \n",
    "assert set(upweighted_features).issubset(feature_names), \"Can't upweight non-existent feature.\"\n",
    "\n",
    "# Upweight some features for distance metric\n",
    "feature_weights = 1 + np.array([f in upweighted_features \n",
    "                                for f in feature_names], dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET EXPERIMENT DATA CONFIGURATION \n",
    "    (after defining feature weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "config = {'metric': 'wminkowski',                               # God does not play dice\n",
    "          'feature_weights' : [feature_weights],\n",
    "          'algorithm': 'auto',                        # Amount of iterations to perform the FQI - S A R S' A'\n",
    "          'Minkowski_Power_parameter': 2, \n",
    "          'n_neighbors': 300,\n",
    "         }\n",
    "config_df = pd.DataFrame(config, index=[0])\n",
    "config_df.to_csv(os.path.join(exp_dir, 'KNN/' + exp_name + '_KNNconfig.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upweighting some of the features for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For TRAIN/VAL/TEST: Create a probability distribution over the action space for each state and save the results as the KNN_PI_behavior_results.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "eval_types = ['train','val','test']\n",
    "for eval_type in eval_types:\n",
    "    eval_since = time.time()\n",
    "    try:\n",
    "        transition_dict = dict(zip(data_dict[eval_type]['state_id'], data_dict[eval_type]['next_state_id']))\n",
    "        print(\"Physician model for: \" + str(eval_type))\n",
    "    except:\n",
    "        print(\"Error using evaluate_model: Incorrect eval type. It should be 'test', 'val' or 'train'\")\n",
    "\n",
    "    # Get model-ready data\n",
    "    state_space = data_dict[eval_type]['X']\n",
    "    state_space[np.where(np.isinf(state_space))] = 0 # impute inf by mean, something with feature 42, ironic isn't it?\n",
    "\n",
    "    # K-Nearest-Neighbor\n",
    "    state_space = data_dict[eval_type]['X']\n",
    "    knn = KNN(n_neighbors=config['n_neighbors'],\n",
    "              metric=config['metric'],\n",
    "              p=config['Minkowski_Power_parameter'],\n",
    "              metric_params={'w': config['feature_weights']},\n",
    "              algorithm=config['algorithm'],\n",
    "              n_jobs=cpu_count()-1)\n",
    "\n",
    "    knn = knn.fit(state_space)\n",
    "    print(str(eval_type) + \" Knn fitted\")\n",
    "\n",
    "    ################################################################################################################\n",
    "    counter = 0\n",
    "    step_size = 50\n",
    "    total_steps = math.floor(state_space.shape[0]/step_size)\n",
    "    final_step = state_space.shape[0] % step_size\n",
    "    print('state space', state_space.shape[0])\n",
    "    print('step size (states in a step):', step_size)\n",
    "    print('final step state space count:', final_step)\n",
    "    print('total steps:', total_steps+1)\n",
    "\n",
    "    ################################################################################################################\n",
    "    for i in range(0,state_space.shape[0],step_size):\n",
    "        ### get subset of state space\n",
    "        if i < total_steps*step_size:\n",
    "            step = step_size\n",
    "        else:\n",
    "            step = final_step\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 10 == 0 or i == 0:\n",
    "            print('step ' + str(counter) + ' out of ' + str(total_steps+1) + '. Start state: ' + str(i) + '. End state: ' + str(i+step*10))\n",
    "\n",
    "        ### get subset of state space\n",
    "        state_space_subset = state_space[i:i+step]\n",
    "\n",
    "        #### get distances and indices\n",
    "        dist_subset, ind_subset = knn.kneighbors(state_space_subset) \n",
    "        if i == 0:\n",
    "            dist, ind = dist_subset, ind_subset\n",
    "        else:\n",
    "            dist = np.append(dist,dist_subset,axis=0)\n",
    "            ind = np.append(ind,ind_subset,axis=0)\n",
    "\n",
    "        ### save interim models every slighty less then 10%\n",
    "        if i % (math.floor(total_steps/10)*step_size) == 0 and i > 0:\n",
    "                saving_step = math.ceil((i / state_space.shape[0])*100)\n",
    "                print('fitted AND SAVED all data up to ' + str(saving_step) + \"%\")\n",
    "                time_elapsed = time.time() - eval_since\n",
    "                hours = time_elapsed//3600\n",
    "                temp = time_elapsed - 3600*hours\n",
    "                minutes = temp//60\n",
    "                seconds = temp - 60*minutes\n",
    "                print('KNN INTERIM STEP completed in %d hours, %d minutes and %d seconds' %(hours,minutes,seconds))\n",
    "                dist_df = pd.DataFrame(dist)\n",
    "                ind_df = pd.DataFrame(ind)\n",
    "                dist_df.to_csv(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_interim_step_' + str(i) + '_' +str(eval_type) + '_dist.csv'), index=False)\n",
    "                ind_df.to_csv(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_interim_step_' + str(i) + '_' +str(eval_type) + '_ind.csv'), index=False)\n",
    "\n",
    "    print(str(eval_type) + \" state space processed\")\n",
    "\n",
    "    ###########################################\n",
    "    all_states_action_probabilities = np.zeros([state_space.shape[0],len(np.unique(data_dict[eval_type]['action']))])\n",
    "    # For each state in the state_space assign the probability of each action to the appropriate column in the final_df\n",
    "    for i in range(state_space.shape[0]):\n",
    "        if i % 5000 == 0: # and i > 0:\n",
    "            print(str(eval_type) + \" APPENDING step \" + str(i) + \" out of \" + str(state_space.shape[0]) + \".\")\n",
    "\n",
    "        # get count of actions for this state\n",
    "        this_state_action = data_dict[eval_type]['action'][(i)]\n",
    "        similar_actions_for_this_state = data_dict[eval_type]['action'][(ind[i])]\n",
    "        all_state_actions= np.append(this_state_action, similar_actions_for_this_state)\n",
    "\n",
    "        # count frequency of each possible (out of ?) actions from (the performed action +  smiliar actions performed by clinicians in similar states)\n",
    "        all_action_count = []\n",
    "\n",
    "        # add the action count of each action for j in action range (0 to unique amount of actions)\n",
    "        for j in np.unique(data_dict[eval_type]['action']):\n",
    "            all_action_count.append(all_state_actions.tolist().count(j))\n",
    "\n",
    "        # get the probability of each action in this state out of [similar_action_for_this_sate+this_state_action]\n",
    "        all_action_probability = [x / sum(all_action_count) for x in all_action_count]\n",
    "        all_action_probs = np.around(all_action_probability,3)\n",
    "\n",
    "        # add to results matrix\n",
    "        all_states_action_probabilities[i,:] = all_action_probs\n",
    "\n",
    "    # visual inspection of final dataframe with assigned action probabilities\n",
    "    results_df = pd.DataFrame.from_records(all_states_action_probabilities)\n",
    "\n",
    "    # save results\n",
    "    results_df.columns = ['A' + str(i) for i in np.unique(data_dict[eval_type]['action'])]\n",
    "\n",
    "    # save to pickle\n",
    "    results_df.to_pickle(os.path.join(exp_dir, 'KNN/KNN_pi_behavior_' + str(eval_type) +'data.pkl'))\n",
    "    \n",
    "    ################################################################################################################\n",
    "    time_elapsed = time.time() - eval_since\n",
    "    hours = time_elapsed//3600\n",
    "    temp = time_elapsed - 3600*hours\n",
    "    minutes = temp//60\n",
    "    seconds = temp - 60*minutes\n",
    "    print('KNN model complete in %d hours, %d minutes and %d seconds' %(hours,minutes,seconds))\n",
    "    print(\"Finished Physician model for \" + str(eval_type) + \" at: \" + str(datetime.now()))\n",
    "    \n",
    "################################################################################################################\n",
    "time_elapsed = time.time() - total_since\n",
    "hours = time_elapsed//3600\n",
    "temp = time_elapsed - 3600*hours\n",
    "minutes = temp//60\n",
    "seconds = temp - 60*minutes\n",
    "print('Total KNN experiment complete in %d hours, %d minutes and %d seconds' %(hours,minutes,seconds))\n",
    "print(\"Finished experiment at: \" + str(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
