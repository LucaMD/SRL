{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "### import overall usefull libraries\n",
    "import os\n",
    "import platform\n",
    "import copy\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "### import specific libraries for this project\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "### import KNN related libraries\n",
    "from sklearn.neighbors import NearestNeighbors as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### import FQI-RandomForest related libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statistics\n",
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "# import from parent directory with a little help from sys.path.insert()\n",
    "sys.path.insert(0, '..') \n",
    "\n",
    "### from util.py (file which once contained all classes and functions):\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from util import * # automatically reload python (e.g. util.py) file when they are changed.\n",
    "\n",
    "### Configuration file to determine root directory \n",
    "import conf\n",
    "\n",
    "# from configuration file set working directory\n",
    "os.chdir(os.path.join(conf.ROOT_DIR, 'SEPSIS'))\n",
    "\n",
    "### check for GPU's\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "### Check everything\n",
    "conf.print_python_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "### Experiment name\n",
    "exp_name = 'FINAL'\n",
    "\n",
    "# This is horrible practice: https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python... but works for now.\n",
    "if not os.path.exists(os.path.join(conf.EXP_DIR, exp_name)):\n",
    "    raise Exception('Cannot find experiment directory, run create_exp_dataset prior to running this file')\n",
    "else:\n",
    "    exp_dir = os.path.join(conf.EXP_DIR, exp_name)\n",
    "    ############################################\n",
    "    # load dataset    \n",
    "    try:\n",
    "        data_dict = joblib.load(os.path.join(exp_dir, 'data/FINAL_data_dict.pkl'))\n",
    "    except:\n",
    "        raise Exception('Cannot load dataset, rerun create_exp_dataset!')\n",
    "\n",
    "    # inspect it (slightly less shitty code then before, still sorry)\n",
    "    print(\"Visual inspection of data dictionary structure:\")\n",
    "    for k, v in data_dict.items():\n",
    "        if(k == 'v'): continue\n",
    "        elif(k == 'featurenames'): \n",
    "            print(v); continue\n",
    "        for k1, v1 in v.items():\n",
    "            print(k, k1)\n",
    "    print(\"\\nExperiment loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET EXPERIMENT DATA CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "################################################################################################################\n",
    "config = {'FQI_SEED': 42,                               # God does not play dice\n",
    "          'gamma': 0.9,\n",
    "          'FQI_iterations': 100,                        # Amount of iterations to perform the FQI - S A R S' A'\n",
    "          'max_depth': 5, \n",
    "          'n_estimators': 80,\n",
    "         }\n",
    "config_df = pd.DataFrame(config, index=[0])\n",
    "config_df.to_csv(os.path.join(exp_dir, 'FQI/' + exp_name + '_FQIconfig.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select evaluation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Before any further steps, decide the dataset to be evaluated\n",
    "eval_type = 'val'\n",
    "\n",
    "# and select how often to train?\n",
    "FQI_iterations = config['FQI_iterations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a continuous feature based state space for the Random Forest(FQI)  model to predict R+y(Q(s,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# get transition dictionary (to determine the end of a trajectory)\n",
    "transition_dict = dict(zip(data_dict[eval_type]['state_id'], data_dict[eval_type]['next_state_id']))\n",
    "\n",
    "# get state_ID's and next_state_ID's\n",
    "batch_ids = data_dict[eval_type]['state_id']\n",
    "next_state_batch_ids = [transition_dict[x] for x in batch_ids]\n",
    "\n",
    "############################################\n",
    "# load the data for the FQI\n",
    "state_features = data_dict[eval_type]['X'][(batch_ids)]\n",
    "state_features[np.where(np.isinf(state_features))] = 0 # impute inf by mean, something with feature 42, ironic isn't it?\n",
    "actions = data_dict[eval_type]['action'][(batch_ids)]\n",
    "reward = data_dict[eval_type]['reward'][(batch_ids)]\n",
    "next_state_features = data_dict[eval_type]['X'][(next_state_batch_ids)]\n",
    "next_state_features[np.where(np.isinf(next_state_features))] = 0\n",
    "# define the reward mask. In case of the end of a trajectory, the MaxQN(state,action) function should be zero... (no more future discounted reward after final state)\n",
    "reward_mask = []\n",
    "for i in range(state_features.shape[0]):\n",
    "    if (batch_ids[i] == next_state_batch_ids[i]):\n",
    "        reward_mask += [False] \n",
    "    else:\n",
    "        reward_mask += [True]\n",
    "\n",
    "# visual inspection of the shape of the state features and the actions\n",
    "print('Check the dimensions of the state and action space:')\n",
    "\n",
    "# next state features\n",
    "print(\"\\nState features:\")\n",
    "print(state_features.shape)\n",
    "\n",
    "# next state features\n",
    "print(\"\\nNext State features:\")\n",
    "print(next_state_features.shape)\n",
    "\n",
    "# action dimensions\n",
    "print(\"\\nUnique Actions:\")\n",
    "print(np.unique(data_dict[eval_type]['action']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build a dataset with with dimensions: all_states * all_possible_actions\n",
    "for i in tqdm(np.unique(data_dict[eval_type]['action'])):\n",
    "    next_state_joined_with_action = np.concatenate((next_state_features, np.transpose([np.repeat(i,next_state_features.shape[0])])), axis=1)\n",
    "    next_state_joined_with_action_joined_with_unique_state_id = np.concatenate((next_state_joined_with_action,np.transpose(np.array([batch_ids]))), axis=1)\n",
    "    if(i==0): \n",
    "        all_next_states_all_possible_actions = pd.DataFrame.from_records(next_state_joined_with_action_joined_with_unique_state_id)\n",
    "        #print(\"\\nDimensions of the dataset that is being appended with it's base length for each action (out of 25):\")\n",
    "        #print(all_next_states_all_possible_actions.shape)\n",
    "    else: \n",
    "        all_next_states_all_possible_actions = all_next_states_all_possible_actions.append(pd.DataFrame.from_records(next_state_joined_with_action_joined_with_unique_state_id))\n",
    "        #print(all_next_states_all_possible_actions.shape)\n",
    "\n",
    "# Add column names for continuous model features\n",
    "feature_names = data_dict['featurenames'].tolist()\n",
    "\n",
    "# Add action to feature space\n",
    "feature_and_action_names = feature_names + ['action']\n",
    "\n",
    "# Add state ID to dataframe \n",
    "column_names = feature_and_action_names + ['state_id']\n",
    "\n",
    "# add the column names to the dataframe\n",
    "all_next_states_all_possible_actions.columns = column_names\n",
    "\n",
    "# visual inspection of the shape of the state features and the actions\n",
    "print('\\nCheck the dimensions of the new state and action space (should be original_state_length * unique_amount_of_actions, feature length + 3 (1 for action, 1 for state_ID, 1 for Qvalue):')\n",
    "print(all_next_states_all_possible_actions.shape)\n",
    "\n",
    "### visual check\n",
    "print(\"\\nVisual check column names of this dataframe:\")\n",
    "print(all_next_states_all_possible_actions.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create action dummies for all_next_states_all_possible_actions dataset and concatenate with the feature dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for actions\n",
    "action_dummies = np.array(pd.get_dummies(actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Random Forest Fitted Q-iteration input (X) and training (feat) dataset\n",
    "    ### Create FQI-RandomForest in \"i\" iterations while learning output = reward + future_discounted_reward given a sum over actions. \n",
    "        This algorithm is trained in a form equal to the objective used in expected S A R S' A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial X (set of states and taken actions at time t from 0 to T)\n",
    "X = np.concatenate([state_features, action_dummies], axis=1)\n",
    "\n",
    "# initialize the Q_minus_1 function, set at 0 for N==0.\n",
    "all_next_states_all_possible_actions[\"Qvalue\"] = 0\n",
    "cont_Q_minus_1 = all_next_states_all_possible_actions.groupby(['state_id'], sort=False)['Qvalue'].max()\n",
    "\n",
    "# construct the output for the regressor function ~ reward mask is False if state is terminal in which case there is no \"future discounted reward, only current state reward\"\\\n",
    "gamma = config['gamma']\n",
    "output = reward + gamma * (cont_Q_minus_1 * reward_mask)\n",
    "\n",
    "feat = np.concatenate([all_next_states_all_possible_actions[feature_names], pd.get_dummies(all_next_states_all_possible_actions['action'])], axis=1)\n",
    "\n",
    "############################################\n",
    "# Create initial RF regressor and set hyperparamters for FQI (gamma for learning, the amount of trees (n_estimators), etc...)\n",
    "cont_regr = RandomForestRegressor(max_depth=config['max_depth'], random_state=config['FQI_SEED'],n_estimators=config['n_estimators'], n_jobs=cpu_count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize first RF regressor (thus, only truly fitting between state_action_pair and immediate reward)\n",
    "cont_regr.fit(X, output)\n",
    "\n",
    "# Before FQI loop:\n",
    "cont_performance_dict = {'train': {\n",
    "                             'iteration':[],\n",
    "                             'loss':[],\n",
    "                             'meanQ': [],\n",
    "                             'Qvar': []\n",
    "                             },\n",
    "                    'val': {\n",
    "                             'iteration':[],\n",
    "                             'loss':[],\n",
    "                             'meanQ': [],\n",
    "                             'Qvar': []\n",
    "                             },\n",
    "                    'test': {\n",
    "                             'iteration':[],                             \n",
    "                             'loss':[],\n",
    "                             'meanQ': [],\n",
    "                             'Qvar': []\n",
    "                             }\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FQI SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop additional times to improve maxQ_n_minus_1(s,a) ~ Function approximator algorithm by FQI: from \"2005 - Tree-Based Batch Mode Reinforcement Learning\"\n",
    "for i in tqdm(range(config['FQI_iterations'])):\n",
    "    # assign new Q values to dataframe\n",
    "    all_next_states_all_possible_actions['Qvalue'] = cont_regr.predict(feat)\n",
    "    \n",
    "    # get max Q value for each state ID # https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby\n",
    "    cont_Q_minus_1 = all_next_states_all_possible_actions.groupby(['state_id'], sort=False)['Qvalue'].max()\n",
    "\n",
    "    # construct the output for the regressor function\n",
    "    output = reward + gamma * (cont_Q_minus_1 * reward_mask)\n",
    "    \n",
    "    # Build the next iteration of the RF regressor\n",
    "    cont_regr.fit(X, output)\n",
    "    \n",
    "    # metric calculation for each loop\n",
    "    loss = (output - cont_Q_minus_1).mean()\n",
    "    meanQ = cont_Q_minus_1.mean()\n",
    "    Qvar = statistics.variance(cont_Q_minus_1)\n",
    "    \n",
    "    # In main loop of the FQI algorithm: Update the performance_dict\n",
    "    cont_performance_dict[eval_type]['iteration'].append(i)\n",
    "    cont_performance_dict[eval_type]['loss'].append(loss)\n",
    "    cont_performance_dict[eval_type]['meanQ'].append(meanQ)\n",
    "    cont_performance_dict[eval_type]['Qvar'].append(Qvar)\n",
    "    \n",
    "    # Keep track of performance\n",
    "    if (i % 10 == 0 and i > 0) or i <25:\n",
    "        print('Iteration: {}, {} Loss: {:4f}, meanQ: {:4f}, Qvar: {:4f}'.format(i, eval_type, loss, meanQ, Qvar))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiplot\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "# Q loss function\n",
    "plt.subplot(141)\n",
    "plt.plot(cont_performance_dict[eval_type]['iteration'], cont_performance_dict[eval_type]['loss'])\n",
    "plt.xlim(0,100)\n",
    "plt.title(\"Iterations step (x) versus loss (y)\")\n",
    "\n",
    "# Q variance plotting\n",
    "plt.subplot(142)\n",
    "plt.plot(cont_performance_dict[eval_type]['iteration'], cont_performance_dict[eval_type]['Qvar'])\n",
    "plt.xlim(0,100)\n",
    "plt.title(\"Iterations step (x) versus Qvalues variance (y)\")\n",
    "\n",
    "# Q variance plotting\n",
    "plt.subplot(143)\n",
    "plt.plot(cont_performance_dict[eval_type]['iteration'], cont_performance_dict[eval_type]['meanQ'])\n",
    "plt.xlim(0,100)\n",
    "plt.title(\"Iterations step (x) versus mean Qvalues (y)\")\n",
    "\n",
    "# Q-value for current_state_joined_with_action\n",
    "plt.subplot(144)\n",
    "pd.Series(cont_Q_minus_1).hist(bins=50)\n",
    "plt.title(\"Qvalue histogram for current state values\")\n",
    "\n",
    "# visual inspection\n",
    "plt.savefig((os.path.join(exp_dir, 'figures/FQI_QValues_continuous_' + str(eval_type) + '.tiff')),dpi=200,transparent=False)\n",
    "plt.show()\n",
    "    \n",
    "# find range for visualisation\n",
    "print(\"Minimal Q Value: \" + str(cont_Q_minus_1.min()))\n",
    "print(\"Maximum Q Value: \" + str(cont_Q_minus_1.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the FQI continuous state space Q-values for each action (the max of these for each state is the V-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build a dataset with with dimensions: all_states * all_possible_actions ~ 6408 (states) * 21 (possible actions)\n",
    "for i in np.unique(data_dict[eval_type]['action']):\n",
    "    current_state_joined_with_action = np.concatenate((state_features, np.transpose([np.repeat(i,state_features.shape[0])])), axis=1)\n",
    "    current_state_joined_with_action_joined_with_unique_state_id = np.concatenate((current_state_joined_with_action,np.transpose(np.array([batch_ids]))), axis=1)\n",
    "    if(i==0): \n",
    "        all_current_states_all_possible_actions = pd.DataFrame.from_records(current_state_joined_with_action_joined_with_unique_state_id)\n",
    "        print(\"\\nDimensions of the dataset that is being appended with it's base length for each action:\")\n",
    "        print(all_current_states_all_possible_actions.shape)\n",
    "    else: \n",
    "        all_current_states_all_possible_actions = all_current_states_all_possible_actions.append(pd.DataFrame.from_records(current_state_joined_with_action_joined_with_unique_state_id))\n",
    "        print(all_current_states_all_possible_actions.shape)\n",
    "\n",
    "# add the column names to the dataframe\n",
    "all_current_states_all_possible_actions.columns = column_names\n",
    "\n",
    "# visual inspection of the shape of the state features and the actions\n",
    "print('\\nCheck the dimensions of the new state and action space (should be original_state_length * unique_amount_of_actions, feature length + 3 (1 for action, 1 for state_ID, 1 for Qvalue):')\n",
    "print(all_current_states_all_possible_actions.shape)\n",
    "\n",
    "### visual check\n",
    "print(\"\\nVisual check column names of this dataframe:\")\n",
    "print(all_current_states_all_possible_actions.columns)\n",
    "\n",
    "# add empty Qvalue column\n",
    "all_current_states_all_possible_actions['Qvalue'] = 0\n",
    "\n",
    "## add dummies back to all_current_states_all_possible_actions\n",
    "current_state_all_possible_actions_dummies = np.concatenate([all_current_states_all_possible_actions[feature_names], pd.get_dummies(all_current_states_all_possible_actions['action'])], axis=1)\n",
    "\n",
    "# assign new Q values to dataframe\n",
    "all_current_states_all_possible_actions['Qvalue'] = cont_regr.predict(current_state_all_possible_actions_dummies)\n",
    "\n",
    "# create an output dataframe with the Q values (25 collumns) for each state (rows) for the 'eval_type' dataset\n",
    "cont_results_df = all_current_states_all_possible_actions.pivot_table(values='Qvalue', index='state_id', columns='action')\n",
    "\n",
    "# add Q values for each unique action\n",
    "cont_results_df.columns = ['Q' + str(i) for i in np.unique(data_dict[eval_type]['action'])]\n",
    "\n",
    "# save to pickle\n",
    "cont_results_df = np.around(cont_results_df,decimals=3)\n",
    "cont_results_df.to_pickle(os.path.join(exp_dir, 'FQI/FQI_QValues_' + str(eval_type) + 'data.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
